{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharath637/python/blob/main/pyspark_arami2_(JSON_DF).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKV4p61s_KsL"
      },
      "source": [
        "# **Arxiv metadata Analytics with PySpark DF: JSON case study**\n",
        "\n",
        "### Udemy Course: Best Hands-on Big Data Practices and Use Cases using PySpark\n",
        "\n",
        "### Author: Amin Karami (PhD, FHEA)\n",
        "#### email: amin.karami@ymail.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r6LNmQMY_KsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3971f1a2-c7c4-435e-a568-f0bbae781824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=aa21a7a226069fb594c6e1c22d9dee06973872369571ba166901699c466a9d47\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "########## ONLY in Colab ##########\n",
        "!pip3 install pyspark\n",
        "########## ONLY in Colab ##########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SIvN-E9n_KsR"
      },
      "outputs": [],
      "source": [
        "########## ONLY in Ubuntu Machine ##########\n",
        "# Load Spark engine\n",
        "!pip3 install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "########## ONLY in Ubuntu Machine ##########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3YlWY9fC_KsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "93935c3d-1c39-4754-d2ad-9bc17d2b7032"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f396a6c7e50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://602db8697a5d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "knOm_f-mInX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9Z3p3JFE_KsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01624d26-65f1-437b-c58e-5258736cff5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- abstract: string (nullable = true)\n",
            " |-- authors: string (nullable = true)\n",
            " |-- authors_parsed: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |-- categories: string (nullable = true)\n",
            " |-- comments: string (nullable = true)\n",
            " |-- doi: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- journal-ref: string (nullable = true)\n",
            " |-- license: string (nullable = true)\n",
            " |-- report-no: string (nullable = true)\n",
            " |-- submitter: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- update_date: string (nullable = true)\n",
            " |-- versions: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- created: string (nullable = true)\n",
            " |    |    |-- version: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read and Load Data to Spark\n",
        "json_arx = spark.read.format(\"json\").load(\"/content/samplearx.json\", multiLine=True)\n",
        "json_arx.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c5ri3G_yGdLT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "viS8zgdO_KsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ba3824-8519-42f8-89d6-a53247018c8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# check the partitions\n",
        "df = json_arx\n",
        "df.rdd.getNumPartitions() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2ivGTrR_KsU"
      },
      "source": [
        "## Question 1: Create a new Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "x9AS1Xz__KsU"
      },
      "outputs": [],
      "source": [
        "# schema prep\n",
        "from pyspark.sql.types import *\n",
        "Schema = StructType (\n",
        "    [\n",
        "                    StructField('authors', StringType(), True),\n",
        "                    StructField('categories', StringType(), True),\n",
        "                    StructField('license', StringType(), True),\n",
        "                    StructField('comments', StringType(), True),\n",
        "                    StructField('abstract', StringType(), True),\n",
        "                    StructField('versions', ArrayType(StringType()), True)\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nqC42SY_KsV"
      },
      "source": [
        "## Question 2: Binding Data to a Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4n3RZ0te_KsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba40e350-e426-4f66-c583-b32c3843a33d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- authors: string (nullable = true)\n",
            " |-- categories: string (nullable = true)\n",
            " |-- license: string (nullable = true)\n",
            " |-- comments: string (nullable = true)\n",
            " |-- abstract: string (nullable = true)\n",
            " |-- versions: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1 = spark.read.json(\"/content/samplearx.json\",schema=Schema,multiLine=True)\n",
        "df1.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8VQA78uRRsc",
        "outputId": "4ffb9c1a-f224-40a6-aefe-e69d181ce12d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+-------+--------------------+--------------------+--------------------+\n",
            "|             authors|categories|license|            comments|            abstract|            versions|\n",
            "+--------------------+----------+-------+--------------------+--------------------+--------------------+\n",
            "|C. Bal\\'azs, E. L...|    hep-ph|   null|37 pages, 15 figu...|  A fully differe...|[{\"version\":\"v1\",...|\n",
            "+--------------------+----------+-------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrizNbnA_KsW"
      },
      "source": [
        "## Question 3: Missing values for \"comments\" and \"license\" attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BElSJl-T_KsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a70b4c-9dbd-4012-a8bd-181666d365e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+-------+--------------------+--------------------+--------------------+\n",
            "|             authors|categories|license|            comments|            abstract|            versions|\n",
            "+--------------------+----------+-------+--------------------+--------------------+--------------------+\n",
            "|C. Bal\\'azs, E. L...|    hep-ph|unknown|37 pages, 15 figu...|  A fully differe...|[{\"version\":\"v1\",...|\n",
            "+--------------------+----------+-------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1.dropna(subset=[\"comments\"])\n",
        "df1.count()\n",
        "df2=df1.fillna(value=\"unknown\",subset=[\"license\"])\n",
        "df2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiAO1VYb_KsX"
      },
      "source": [
        "## Question 4: Get the author names who published a paper in a 'math' category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "le9Cfbnk_KsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ddfb5cc-3bb2-40a2-b8b3-c6d3bd80d971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+--------+--------+--------+\n",
            "|authors|categories|license|comments|abstract|versions|\n",
            "+-------+----------+-------+--------+--------+--------+\n",
            "+-------+----------+-------+--------+--------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df2.createOrReplaceTempView(\"Archive\")\n",
        "\n",
        "sql_q = \"select * from Archive where categories LIKE 'math%' \"\n",
        "\n",
        "dd=spark.sql(sql_q)\n",
        "dd.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5thkuIv_KsY"
      },
      "source": [
        "## Question 5: Get linceses with 5 or more letters in the \"abstract\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "B7LLuIkk_KsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d092f4-9cf4-4582-a029-51f2a81506fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.get_Page(line)>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "sql_query1 = \"\"\" SELECT versions,comments FROM Archive\n",
        "            \"\"\"\n",
        "spark.sql(sql_query1).collect()\n",
        "\n",
        "import re\n",
        "def get_Page(line):\n",
        "    search = re.findall('\\d+ pages', line)\n",
        "    if search:\n",
        "        return search[0].split(\" \")[0]\n",
        "    else:\n",
        "        return 0\n",
        "#get_Page('37 pages, 15 figures')\n",
        "spark.udf.register(\"get_page_num\",get_Page)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3=df2.withColumn(\"versions_str\",df2.versions.cast(StringType()))\n",
        "df4 = df3.select(df3.comments,substring(substring_index(substring_index(df3.versions_str,\":\",3),\",\",-2),12,3).alias('extract_day'))\n",
        "df4.show(truncate=False)\n",
        "#df.select(substring_index(df.s, '.', 2).alias('s')).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYo1xhlLdEN2",
        "outputId": "3acbfd21-71e8-4c3c-8d95-7f044d26600c"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------+-----------+\n",
            "|comments                               |extract_day|\n",
            "+---------------------------------------+-----------+\n",
            "|37 pages, 15 figures; published version|Mon        |\n",
            "+---------------------------------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df1 = spark.read.json(\"/content/samplearx.json\",schema=Schema,multiLine=True)\n",
        "df2=df1.withColumn(\"versions_str\",df1.versions.cast(StringType()))\n",
        "df3=df2.select(df2.comments,substring(substring_index(substring_index(df2.versions_str,\":\",3),\",\",-2),12,3).alias('extract_day'))\n",
        "df3.createOrReplaceTempView(\"Archive\")\n",
        "#get Page Function\n",
        "import re\n",
        "def get_Page(line):\n",
        "    search = re.findall('\\d+ pages', line)\n",
        "    if search:\n",
        "        return search[0].split(\" \")[0]\n",
        "    else:\n",
        "        return 0\n",
        "#get_Page('37 pages, 15 figures')\n",
        "spark.udf.register(\"get_page_num\",get_Page)\n",
        "sql_q = \"\"\"select avg(get_page_num(comments)) as average_num_of_page_per_day,extract_day from Archive \n",
        "            where get_page_num(comments) <> 0 group by extract_day  \n",
        "        \"\"\"\n",
        "dd=spark.sql(sql_q)\n",
        "dd.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSHjyzcsirAl",
        "outputId": "2eadeacf-9af6-47f9-c907-ee240d8b9024"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------+-----------+\n",
            "|average_num_of_page_per_day|extract_day|\n",
            "+---------------------------+-----------+\n",
            "|67.5                       |Mon        |\n",
            "+---------------------------+-----------+\n",
            "\n",
            "CPU times: user 28 ms, sys: 4.52 ms, total: 32.5 ms\n",
            "Wall time: 757 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_Page('None')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv0jAwYstX-s",
        "outputId": "b4c583fa-eca5-4b58-a633-f6886266b503"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjELziqH_KsZ"
      },
      "source": [
        "## Question 6: Extract the statistic of the number of pages for unknown licenses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1DYmkI8_KsZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}